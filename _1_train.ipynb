{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f90381",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "import sklearn\n",
    "from sklearn import metrics\n",
    "import seaborn as sns\n",
    "tf.__version__, sklearn.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e11987",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "tf.random.set_seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc6ad1a4",
   "metadata": {},
   "source": [
    "# 1. Setup dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f935d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup dataset\n",
    "\n",
    "%run \"./setup_dataset.ipynb\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6040d4a",
   "metadata": {},
   "source": [
    "# 2. Train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9429acd",
   "metadata": {},
   "source": [
    "### 2.1 modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da498a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model\n",
    "\n",
    "def create_model(activation=\"relu\", dropout=0.1, input_shape=(150,150,3), nb_classes=3):\n",
    "    model = models.Sequential()\n",
    "    \n",
    "    model.add(layers.Input(input_shape))\n",
    "    \n",
    "    # model.add(layers.Conv2D(32, (3,3), input_shape=input_shape))\n",
    "    model.add(layers.Conv2D(32, (3,3)))\n",
    "    model.add(layers.Activation(activation))\n",
    "    model.add(layers.Dropout(dropout))\n",
    "    model.add(layers.MaxPooling2D((2,2)))\n",
    "\n",
    "    model.add(layers.Conv2D(64, (3,3)))\n",
    "    model.add(layers.Activation(activation))\n",
    "    model.add(layers.Dropout(dropout))\n",
    "    model.add(layers.MaxPooling2D((2,2)))\n",
    "\n",
    "    model.add(layers.Conv2D(128, (3,3)))\n",
    "    model.add(layers.Activation(activation))\n",
    "    model.add(layers.Dropout(dropout))\n",
    "    model.add(layers.MaxPooling2D((2,2)))\n",
    "\n",
    "    model.add(layers.Conv2D(128, (3,3)))\n",
    "    model.add(layers.Activation(activation))\n",
    "    model.add(layers.Dropout(dropout))\n",
    "    model.add(layers.MaxPooling2D((2,2)))\n",
    "\n",
    "    model.add(layers.Flatten())\n",
    "\n",
    "    model.add(layers.Dense(512, activation=activation))\n",
    "    model.add(layers.Dense(nb_classes, activation='softmax'))\n",
    "\n",
    "    return model\n",
    "\n",
    "    \n",
    "model = create_model(activation=\"relu\", dropout=0.3, input_shape=(150,150,3), nb_classes=3)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caca6f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile model\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=tf.keras.optimizers.Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, amsgrad=False),\n",
    "              metrics=['accuracy'])\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c77b2eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define generator\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "batch_size = 10\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(150, 150),  # Resize all images to 150x150.\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    ")\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    validation_dir,\n",
    "    target_size=(150, 150),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f3711c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # define generator with data augumentation\n",
    "\n",
    "# train_datagen = ImageDataGenerator(\n",
    "#     rescale=1./255,\n",
    "#     rotation_range=40,\n",
    "#     width_shift_range=0.2,\n",
    "#     height_shift_range=0.2,\n",
    "#     shear_range=0.2,\n",
    "#     zoom_range=0.2,\n",
    "#     horizontal_flip=True,)\n",
    "\n",
    "# test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# batch_size = 10\n",
    "\n",
    "# train_generator = train_datagen.flow_from_directory(\n",
    "#     train_dir,\n",
    "#     target_size=(150, 150),  # Resize all images to 150x150.\n",
    "#     batch_size=batch_size,\n",
    "#     class_mode='categorical',\n",
    "# )\n",
    "\n",
    "# validation_generator = test_datagen.flow_from_directory(\n",
    "#     validation_dir,\n",
    "#     target_size=(150, 150),\n",
    "#     batch_size=batch_size,\n",
    "#     class_mode='categorical',\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4296b085",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set early-stopping\n",
    "\n",
    "best_model = f\"best_model_{tf.__version__}.keras\"\n",
    "\n",
    "callbacks = [EarlyStopping(monitor=\"val_loss\", min_delta=1e-5, patience=10, mode=\"auto\", verbose=0),\n",
    "             ModelCheckpoint(filepath=os.path.join(MODEL_DIR, best_model), monitor=\"val_loss\", save_best_only=True, save_weights_only=False),\n",
    "             ReduceLROnPlateau(monitor=\"val_loss\", factor=0.1, patience=10),  # divide learning_rate by 10 when the callback is invoked.\n",
    "            ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4099c8f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "\n",
    "epochs = 30\n",
    "# epochs = 2\n",
    "\n",
    "begin_time = datetime.now()\n",
    "\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=epochs,\n",
    "    validation_data=validation_generator,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1,\n",
    ")\n",
    "\n",
    "print(\"\\nElapsed Time: {}\\t{}\".format(datetime.now() - begin_time, datetime.now()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd49b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw convergence history\n",
    "\n",
    "def draw_convergence_history(history, save_file=None):\n",
    "    \"\"\"draw convergence history\"\"\"\n",
    "    \n",
    "    _, ax = plt.subplots(1,2, figsize=(10,4), facecolor=\"w\")\n",
    "    \n",
    "    # obtain the history of training loss and validation loss\n",
    "    training_loss = history[\"loss\"]\n",
    "    validation_loss = history[\"val_loss\"]\n",
    "\n",
    "    # prepare epoch list\n",
    "    epoch_count = range(1, len(training_loss) + 1)\n",
    "    \n",
    "    # plot \"loss convergence\" for training data and validation data\n",
    "    ax[0].plot(epoch_count, training_loss, \"rx--\")  # r-- ro ro- ro--\n",
    "    ax[0].plot(epoch_count, validation_loss, \"bo-\")\n",
    "    \n",
    "    ax[0].set_title(\"convergence history of loss\")\n",
    "    ax[0].legend([\"Training Loss\", \"Validation Loss\"], loc=\"upper right\")\n",
    "    ax[0].set_xlabel(\"Epoch\")\n",
    "    ax[0].set_ylabel(\"Loss\")\n",
    "    ax[0].grid()\n",
    "\n",
    "    # plot \"accuracy convergence\" for training data and validation data\n",
    "    training_accuracy = history[\"accuracy\"]\n",
    "    validation_accuracy = history[\"val_accuracy\"]\n",
    "    \n",
    "    ax[1].plot(epoch_count, training_accuracy, \"rx--\")  # r-- ro ro- ro--\n",
    "    ax[1].plot(epoch_count, validation_accuracy, \"bo-\")\n",
    "    \n",
    "    ax[1].set_title(\"convergence history of score\")\n",
    "    ax[1].legend([\"Training Score\", \"Validation Score\"], loc=\"lower right\")\n",
    "    ax[1].set_xlabel(\"Epoch\")\n",
    "    ax[1].set_ylabel(\"Score\")\n",
    "    ax[1].grid()\n",
    "\n",
    "    if save_file:\n",
    "        plt.savefig(save_file)\n",
    "\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "draw_convergence_history(history.history, save_file=Path(OUTPUT_DIR, \"convergence_history.png\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd869f99",
   "metadata": {},
   "source": [
    "### 2.2 Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64de98b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define generator\n",
    "\n",
    "batch_size = 10\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(150, 150),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce1d03d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate loss and accuracy\n",
    "\n",
    "loss, accuracy = model.evaluate(test_generator, verbose=1)\n",
    "print(f\"{loss= :.4f}\\t{accuracy= :.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d163de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict testset\n",
    "\n",
    "test_pred_dict = {}\n",
    "\n",
    "for test_dir in test_dirs:\n",
    "    pred = []\n",
    "        \n",
    "    for path in test_dir.iterdir():\n",
    "#         print(path)\n",
    "        img = image.load_img(path, target_size=(150, 150))\n",
    "        img_tensor = image.img_to_array(img)\n",
    "        img_tensor = np.expand_dims(img_tensor, axis=0)\n",
    "        img_tensor /= 255.\n",
    "\n",
    "        p = model.predict(img_tensor)[0]\n",
    "        pred.append(np.argmax(p))\n",
    "    \n",
    "    test_pred_dict[test_dir.name] = pred\n",
    "\n",
    "\n",
    "test_pred = [*test_pred_dict[\"salad\"], *test_pred_dict[\"sushi\"], *test_pred_dict[\"tofu\"]]\n",
    "print(test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae19daa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create ture class list \n",
    "\n",
    "num_of_salad = len(os.listdir(test_salad_dir))\n",
    "num_of_sushi = len(os.listdir(test_sushi_dir))\n",
    "num_of_tofu = len(os.listdir(test_tofu_dir))\n",
    "\n",
    "test_true = [*[0]*num_of_salad, *[1]*num_of_sushi, *[2]*num_of_tofu]\n",
    "print(test_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41276345",
   "metadata": {},
   "outputs": [],
   "source": [
    "# classification report\n",
    "\n",
    "report = metrics.classification_report(test_true, test_pred)\n",
    "\n",
    "print(f\"classification report on test dataset\\n{report}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b139408",
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion matrix\n",
    "\n",
    "confusion_matrix = metrics.confusion_matrix(test_true, test_pred)\n",
    "\n",
    "sns.heatmap(confusion_matrix, annot=True, cmap=\"Blues\", fmt=\"d\")\n",
    "\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "    \n",
    "plt.savefig(Path(OUTPUT_DIR, \"confusionmatrix.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1224b1d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env (3.13.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
